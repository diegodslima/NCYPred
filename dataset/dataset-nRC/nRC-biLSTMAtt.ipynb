{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6nEEqesdy0cL"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G61xcVnszcUQ"
   },
   "source": [
    "## Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MX_9jH3SzdCA"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./nRC-training-set.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "wXiw_r3mtifj"
   },
   "outputs": [],
   "source": [
    "# One-hot encoding das classes\n",
    "one_hot_labels = pd.get_dummies(df_train['labels']).values\n",
    "df_train['b-labels'] = list(one_hot_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "Rj_L_5qKtmN3",
    "outputId": "3dd94764-beb0-4302-c35d-83bf52ccf905"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "      <th>seq</th>\n",
       "      <th>labels</th>\n",
       "      <th>b-labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF00001_AF095839_1_346-228</td>\n",
       "      <td>GCGTACGGCCATACTATGGGGAATACACCTGATCCCGTCCGATTTC...</td>\n",
       "      <td>5S_rRNA</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF00001_AY245018_1_1-119</td>\n",
       "      <td>GCTATCGGCCATACTAAGCCAAATGCACCGGATCCCTTCCGAACTC...</td>\n",
       "      <td>5S_rRNA</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF00001_X52048_1_2-120</td>\n",
       "      <td>TGCTACGATCATACCACTTAGAAAGCACCCGGTCCCATCAGACCCC...</td>\n",
       "      <td>5S_rRNA</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF00001_M28193_1_1-119</td>\n",
       "      <td>AGTTACGGCCATACCTCAGAGAATATACCGTATCCCGTTCGATCTG...</td>\n",
       "      <td>5S_rRNA</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF00001_X14816_1_860-978</td>\n",
       "      <td>ACCAACGGCCATACCACGTTGAAAGTACCCAGTCTCGTCAGATCCT...</td>\n",
       "      <td>5S_rRNA</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6315</th>\n",
       "      <td>RF02535_AFEY01343643_1_18075-17945</td>\n",
       "      <td>ACTTCCAATGCAATGGCTGCAGTGAAGCTATAATTATAGCCTTGTA...</td>\n",
       "      <td>IRES</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6316</th>\n",
       "      <td>RF02535_AAPE02009951_1_24083-24245</td>\n",
       "      <td>ATTCCCAGTGCTGCACCGAGAGGACCTGTCTCCTGTGGACTGGAAG...</td>\n",
       "      <td>IRES</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6317</th>\n",
       "      <td>RF02535_ABQO011108623_1_28-199</td>\n",
       "      <td>AGTGCAACGGCTGCACCGAAGGCACAATCGTAGCCTTGTATTTCAC...</td>\n",
       "      <td>IRES</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6318</th>\n",
       "      <td>RF02535_AAPE02044716_1_11582-11441</td>\n",
       "      <td>ATTCCCGCTGCTGCACAGAGAGGACCCGTGTCCCGTGGACTGGGAG...</td>\n",
       "      <td>IRES</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6319</th>\n",
       "      <td>RF02535_AEYP01041088_1_4708-4575</td>\n",
       "      <td>AGTCCCAATATTGCATCCAACAGGATTTGGAATTTCTAGAGAATTG...</td>\n",
       "      <td>IRES</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6320 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ids  \\\n",
       "0             RF00001_AF095839_1_346-228   \n",
       "1               RF00001_AY245018_1_1-119   \n",
       "2                 RF00001_X52048_1_2-120   \n",
       "3                 RF00001_M28193_1_1-119   \n",
       "4               RF00001_X14816_1_860-978   \n",
       "...                                  ...   \n",
       "6315  RF02535_AFEY01343643_1_18075-17945   \n",
       "6316  RF02535_AAPE02009951_1_24083-24245   \n",
       "6317      RF02535_ABQO011108623_1_28-199   \n",
       "6318  RF02535_AAPE02044716_1_11582-11441   \n",
       "6319    RF02535_AEYP01041088_1_4708-4575   \n",
       "\n",
       "                                                    seq   labels  \\\n",
       "0     GCGTACGGCCATACTATGGGGAATACACCTGATCCCGTCCGATTTC...  5S_rRNA   \n",
       "1     GCTATCGGCCATACTAAGCCAAATGCACCGGATCCCTTCCGAACTC...  5S_rRNA   \n",
       "2     TGCTACGATCATACCACTTAGAAAGCACCCGGTCCCATCAGACCCC...  5S_rRNA   \n",
       "3     AGTTACGGCCATACCTCAGAGAATATACCGTATCCCGTTCGATCTG...  5S_rRNA   \n",
       "4     ACCAACGGCCATACCACGTTGAAAGTACCCAGTCTCGTCAGATCCT...  5S_rRNA   \n",
       "...                                                 ...      ...   \n",
       "6315  ACTTCCAATGCAATGGCTGCAGTGAAGCTATAATTATAGCCTTGTA...     IRES   \n",
       "6316  ATTCCCAGTGCTGCACCGAGAGGACCTGTCTCCTGTGGACTGGAAG...     IRES   \n",
       "6317  AGTGCAACGGCTGCACCGAAGGCACAATCGTAGCCTTGTATTTCAC...     IRES   \n",
       "6318  ATTCCCGCTGCTGCACAGAGAGGACCCGTGTCCCGTGGACTGGGAG...     IRES   \n",
       "6319  AGTCCCAATATTGCATCCAACAGGATTTGGAATTTCTAGAGAATTG...     IRES   \n",
       "\n",
       "                                     b-labels  \n",
       "0     [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1     [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "2     [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "3     [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "4     [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "...                                       ...  \n",
       "6315  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "6316  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "6317  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "6318  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "6319  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "\n",
       "[6320 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "df_train = shuffle(df_train)\n",
    "df_train = df_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "      <th>seq</th>\n",
       "      <th>labels</th>\n",
       "      <th>b-labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF00001_AAWZ02019646_1_204701-204588</td>\n",
       "      <td>AGGTAGGGTTGCAATAAAGGCACCAGATCCCATTACATCTTGGAAA...</td>\n",
       "      <td>5S_rRNA</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF00002_AJ307679_1_897-1055</td>\n",
       "      <td>GACCCTGGGGGATGGATCACTCGGCTCGTATTACGAAGACGAACGC...</td>\n",
       "      <td>5_8S_rRNA</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF00001_AAQR03010791_1_33267-33380</td>\n",
       "      <td>ATCAATGGCCATACCCCTCTGAAAGTACCTGATCTTGTCTGATCTT...</td>\n",
       "      <td>5S_rRNA</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF00223_ABRT010369175_1_885-1057</td>\n",
       "      <td>CACCAACCAAGACAGCATCTCACAGATCTACTTGTGTGTTTCCAGA...</td>\n",
       "      <td>IRES</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF00778_FN596251_1_1049963-1050065</td>\n",
       "      <td>GTTGCTCACTCTCCCTCAAGGGCTTCTGCACTTTGGCCATGGCCAT...</td>\n",
       "      <td>miRNA</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6315</th>\n",
       "      <td>RF00557_CP002728_1_2259604-2259443</td>\n",
       "      <td>TTATTGTTATATATTATGCTGCAGACCGTAGGTGCTATAAAGCTTA...</td>\n",
       "      <td>leader</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6316</th>\n",
       "      <td>RF00449_AAGU03024943_1_27857-28130</td>\n",
       "      <td>CTGGTCTGAGGGAAGGCGAGGATCGCCCTCGCCGCCGGTTCGGCCA...</td>\n",
       "      <td>IRES</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6317</th>\n",
       "      <td>RF00001_AFYH01166467_1_4673-4555</td>\n",
       "      <td>AAAAAGAGGCACAGTAGGACCCCAGTGCCTGGTCTTGTCTGATCTC...</td>\n",
       "      <td>5S_rRNA</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6318</th>\n",
       "      <td>RF01057_CAFE01000042_1_5903-6040</td>\n",
       "      <td>GTCTTCGAGGAGCGTTGCGACGGGCAAACGGCTGAAAAACACCGCC...</td>\n",
       "      <td>riboswitch</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6319</th>\n",
       "      <td>RF00001_AANN01783413_1_845-719</td>\n",
       "      <td>GTCTAAGGCCATACCAGCCCAAACATGCCCGATCTCATCTGATCTC...</td>\n",
       "      <td>5S_rRNA</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6320 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       ids  \\\n",
       "0     RF00001_AAWZ02019646_1_204701-204588   \n",
       "1              RF00002_AJ307679_1_897-1055   \n",
       "2       RF00001_AAQR03010791_1_33267-33380   \n",
       "3         RF00223_ABRT010369175_1_885-1057   \n",
       "4       RF00778_FN596251_1_1049963-1050065   \n",
       "...                                    ...   \n",
       "6315    RF00557_CP002728_1_2259604-2259443   \n",
       "6316    RF00449_AAGU03024943_1_27857-28130   \n",
       "6317      RF00001_AFYH01166467_1_4673-4555   \n",
       "6318      RF01057_CAFE01000042_1_5903-6040   \n",
       "6319        RF00001_AANN01783413_1_845-719   \n",
       "\n",
       "                                                    seq      labels  \\\n",
       "0     AGGTAGGGTTGCAATAAAGGCACCAGATCCCATTACATCTTGGAAA...     5S_rRNA   \n",
       "1     GACCCTGGGGGATGGATCACTCGGCTCGTATTACGAAGACGAACGC...   5_8S_rRNA   \n",
       "2     ATCAATGGCCATACCCCTCTGAAAGTACCTGATCTTGTCTGATCTT...     5S_rRNA   \n",
       "3     CACCAACCAAGACAGCATCTCACAGATCTACTTGTGTGTTTCCAGA...        IRES   \n",
       "4     GTTGCTCACTCTCCCTCAAGGGCTTCTGCACTTTGGCCATGGCCAT...       miRNA   \n",
       "...                                                 ...         ...   \n",
       "6315  TTATTGTTATATATTATGCTGCAGACCGTAGGTGCTATAAAGCTTA...      leader   \n",
       "6316  CTGGTCTGAGGGAAGGCGAGGATCGCCCTCGCCGCCGGTTCGGCCA...        IRES   \n",
       "6317  AAAAAGAGGCACAGTAGGACCCCAGTGCCTGGTCTTGTCTGATCTC...     5S_rRNA   \n",
       "6318  GTCTTCGAGGAGCGTTGCGACGGGCAAACGGCTGAAAAACACCGCC...  riboswitch   \n",
       "6319  GTCTAAGGCCATACCAGCCCAAACATGCCCGATCTCATCTGATCTC...     5S_rRNA   \n",
       "\n",
       "                                     b-labels  \n",
       "0     [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1     [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "2     [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "3     [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]  \n",
       "...                                       ...  \n",
       "6315  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]  \n",
       "6316  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "6317  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "6318  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]  \n",
       "6319  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "\n",
       "[6320 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9f9N7xjFzljQ"
   },
   "source": [
    "## Gerar tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "U0J3Phhbzl6C"
   },
   "outputs": [],
   "source": [
    "def seq_to_3mer(seq_list):\n",
    "\tprint('Processing {} sequences'.format(len(seq_list)))\n",
    "\t\n",
    "\tmain_list = []\n",
    "\t\n",
    "\tfor _, i in enumerate(seq_list):\n",
    "\t\t# print('type(i): ', type(i))\n",
    "\t\t# print('type([i]): ', type([i]))\n",
    "\t\t# print('type(list(i)): ', type(list(i)))\n",
    "\t\tseq = list(i)\n",
    "\t\tseq_kmer = []\n",
    "\n",
    "\t\tfor j, _ in enumerate(seq):\n",
    "\t\t\tif j < len(seq) - 2:\n",
    "\t\t\t\tseq_kmer.append(seq[j] + seq[j+1] + seq[j+2])\n",
    "\t\t\telse:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\tmain_list.append(seq_kmer)\n",
    "\n",
    "\treturn main_list \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 6320 sequences\n"
     ]
    }
   ],
   "source": [
    "# Gerar k-mers\n",
    "X_3mer = seq_to_3mer(df_train['seq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1134"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_length = []\n",
    "for x in X_3mer:\n",
    "    seq_length.append(len(x))\n",
    "    \n",
    "seq_length.sort()\n",
    "seq_length[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "MAX_VOCAB_SIZE = 600\n",
    "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(X_3mer)\n",
    "idx = tokenizer.word_index\n",
    "print(len(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# saving tokenizer\n",
    "with open('tokenizer-nRC-alltokens.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_pad(sentences, max_len, prefix):\n",
    "\tprint('Zero-padding sequences to {} and tokenizing'.format(max_len))\n",
    "\n",
    "\twith open('./tokenizer-nRC-alltokens.pickle', 'rb') as handle:\n",
    "\t\ttokenizer = pickle.load(handle)\n",
    "\n",
    "\ttokens = tokenizer.texts_to_sequences(sentences)\n",
    "\tall_pad = pad_sequences(tokens, max_len, padding=prefix)\n",
    "\n",
    "\treturn all_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ShBAvGetzq9T",
    "outputId": "7067f6d5-4ffc-415d-c864-895a52e115f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-padding sequences to 1134 and tokenizing\n"
     ]
    }
   ],
   "source": [
    "# Tokenization and zero-padding\n",
    "X = token_pad(X_3mer, 1134, 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lFxv3wqFztSi",
    "outputId": "a31ba9cb-4210-4489-8abb-2c7cb5b82ade"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12, 16, 53, ...,  0,  0,  0],\n",
       "       [52, 50, 25, ...,  0,  0,  0],\n",
       "       [48, 40, 33, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [ 1,  1,  1, ...,  0,  0,  0],\n",
       "       [55, 30, 26, ...,  0,  0,  0],\n",
       "       [55, 30, 58, ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "g7-jei5ZtvWk"
   },
   "outputs": [],
   "source": [
    "array_list = []\n",
    "for arr in list(df_train['b-labels']):\n",
    "    array_list.append(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "k5yINPodz_wc"
   },
   "outputs": [],
   "source": [
    "y = np.vstack(array_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mpj-fCzq0CI4",
    "outputId": "da7b1940-2d03-4a25-a5ed-b32d6281004e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6320, 1134)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6320, 13)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "226nHCbuo8bj"
   },
   "source": [
    "# Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "7iBxaze1o-Oj"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Concatenate, Dense, Input, LSTM, Embedding, Dropout, Activation, Attention, Flatten, SimpleRNN\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import AdditiveAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "igmYOWLajFQS"
   },
   "outputs": [],
   "source": [
    "def biLSTM(lr, D):\n",
    "\n",
    "\n",
    "    sequence_input = Input(shape=(498,), dtype=\"int32\")\n",
    "    embedded_sequences = Embedding(64, D, mask_zero=True)(sequence_input)\n",
    "\n",
    "\n",
    "    lstm = Bidirectional(LSTM(32, input_shape=(498, D), return_sequences=False,\n",
    "                            return_state=False), name=\"bilstm1\")(embedded_sequences)\n",
    "\n",
    "    dense1 = Dense(128, activation=\"relu\")(lstm)\n",
    "    dropout = Dropout(0.4)(dense1)\n",
    "    output = Dense(13, activation='softmax')(dropout)\n",
    "\n",
    "    model = tf.keras.Model(inputs=sequence_input, outputs=output)\n",
    "  \n",
    "    # compile model\n",
    "    opt = tf.keras.optimizers.RMSprop(learning_rate=lr, momentum=0.01, centered=True)\n",
    "  \n",
    "    METRICS = [\n",
    "\t  tf.keras.metrics.TruePositives(name='tp'),\n",
    "\t  tf.keras.metrics.FalsePositives(name='fp'),\n",
    "  \ttf.keras.metrics.TrueNegatives(name='tn'),\n",
    "\t  tf.keras.metrics.FalseNegatives(name='fn'),\n",
    "\t  tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "\t  tf.keras.metrics.Precision(name='precision'),\n",
    "\t  tf.keras.metrics.Recall(name='recall'),\n",
    "\t  tf.keras.metrics.AUC(name='auc'),\n",
    "    ]\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=opt,\n",
    "                metrics=METRICS)\n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "myWpoE3Ikzk_",
    "outputId": "a7ccf605-af30-4490-a59a-d24e0b9ca992"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 498)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 498, 10)           640       \n",
      "_________________________________________________________________\n",
      "bilstm1 (Bidirectional)      (None, 64)                11008     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 13)                1677      \n",
      "=================================================================\n",
      "Total params: 21,645\n",
      "Trainable params: 21,645\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = biLSTM(0.004, 10)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "kzeFMQAXW3_l"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import initializers, regularizers, constraints\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "# https://gist.github.com/cbaziotis/6428df359af27d58078ca5ed9792bd6d\n",
    "\n",
    "def dot_product(x, kernel):\n",
    "    \"\"\"\n",
    "    Wrapper for dot product operation, in order to be compatible with both\n",
    "    Theano and Tensorflow\n",
    "    Args:\n",
    "        x (): input\n",
    "        kernel (): weights\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    if K.backend() == 'tensorflow':\n",
    "        # todo: check that this is correct\n",
    "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
    "    else:\n",
    "        return K.dot(x, kernel)\n",
    "\n",
    "\n",
    "class Attention(Layer):\n",
    "    def __init__(self,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True,\n",
    "                 return_attention=False,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        Keras Layer that implements an Attention mechanism for temporal data.\n",
    "        Supports Masking.\n",
    "        Follows the work of Raffel et al. [https://arxiv.org/abs/1512.08756]\n",
    "        # Input shape\n",
    "            3D tensor with shape: `(samples, steps, features)`.\n",
    "        # Output shape\n",
    "            2D tensor with shape: `(samples, features)`.\n",
    "        :param kwargs:\n",
    "        Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "        The dimensions are inferred based on the output shape of the RNN.\n",
    "\n",
    "\n",
    "        Note: The layer has been tested with Keras 1.x\n",
    "\n",
    "        Example:\n",
    "        \n",
    "            # 1\n",
    "            model.add(LSTM(64, return_sequences=True))\n",
    "            model.add(Attention())\n",
    "            # next add a Dense layer (for classification/regression) or whatever...\n",
    "\n",
    "            # 2 - Get the attention scores\n",
    "            hidden = LSTM(64, return_sequences=True)(words)\n",
    "            sentence, word_scores = Attention(return_attention=True)(hidden)\n",
    "\n",
    "        \"\"\"\n",
    "        self.supports_masking = True\n",
    "        self.return_attention = return_attention\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight(shape=(input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight(shape=(input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        eij = dot_product(x, self.W)\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
    "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        weighted_input = x * K.expand_dims(a)\n",
    "\n",
    "        result = K.sum(weighted_input, axis=1)\n",
    "\n",
    "        if self.return_attention:\n",
    "            return [result, a]\n",
    "        return result\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.return_attention:\n",
    "            return [(input_shape[0], input_shape[-1]),\n",
    "                    (input_shape[0], input_shape[1])]\n",
    "        else:\n",
    "            return input_shape[0], input_shape[-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "q_GvoDK2W7wC"
   },
   "outputs": [],
   "source": [
    "def biLSTMAtt(lr, D):\n",
    "\n",
    "\n",
    "    sequence_input = Input(shape=(1134,), dtype=\"int32\")\n",
    "    embedded_sequences = Embedding(583, D, mask_zero=True)(sequence_input)\n",
    "\n",
    "    (lstm, forward_h, forward_c, \n",
    "        backward_h, backward_c) = Bidirectional(LSTM(32, input_shape=(1134, D), return_sequences=True,\n",
    "                                                  return_state=True), name=\"bi_lstm_1\")(embedded_sequences)\n",
    "\n",
    "    state_h = Concatenate()([forward_h, backward_h])\n",
    "    state_c = Concatenate()([forward_c, backward_c])\n",
    "\n",
    "    context_vector, weights = Attention(return_attention=True)(lstm)\n",
    "\n",
    "    dense1 = Dense(128, activation=\"relu\")(context_vector)\n",
    "    dropout = Dropout(0.4)(dense1)\n",
    "    output = Dense(13, activation='softmax')(dropout)\n",
    "\n",
    "    model = tf.keras.Model(inputs=sequence_input, outputs=output)\n",
    "  \n",
    "    # compile model\n",
    "    opt = tf.keras.optimizers.RMSprop(learning_rate=lr, momentum=0.01, centered=True)\n",
    "  \n",
    "    METRICS = [\n",
    "\t  tf.keras.metrics.TruePositives(name='tp'),\n",
    "\t  tf.keras.metrics.FalsePositives(name='fp'),\n",
    "  \ttf.keras.metrics.TrueNegatives(name='tn'),\n",
    "\t  tf.keras.metrics.FalseNegatives(name='fn'),\n",
    "\t  tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "\t  tf.keras.metrics.Precision(name='precision'),\n",
    "\t  tf.keras.metrics.Recall(name='recall'),\n",
    "\t  tf.keras.metrics.AUC(name='auc'),\n",
    "    ]\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=opt,\n",
    "                metrics=METRICS)\n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5TNvWWg8XCEo",
    "outputId": "0b59f9c1-9195-41ac-e148-a42084a76114"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 1134)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_6 (Embedding)      (None, 1134, 10)          5830      \n",
      "_________________________________________________________________\n",
      "bi_lstm_1 (Bidirectional)    [(None, 1134, 64), (None, 11008     \n",
      "_________________________________________________________________\n",
      "attention_2 (Attention)      [(None, 64), (None, 1134) 1198      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 13)                1677      \n",
      "=================================================================\n",
      "Total params: 28,033\n",
      "Trainable params: 28,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = biLSTMAtt(0.004, 10)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ssq6bHExvA0y"
   },
   "source": [
    "# K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def CreateFolds(X, y, folds, test_size):\n",
    "\n",
    "    sss = StratifiedShuffleSplit(n_splits=folds, test_size=test_size)\n",
    "    sss.get_n_splits(X, y)\n",
    "\n",
    "    count = 1\n",
    "\n",
    "    train_list = []\n",
    "    test_list = []\n",
    "\n",
    "    for train_index, test_index in sss.split(X, y):\n",
    "        print('Fold {}'.format(count))\n",
    "\n",
    "        train_list.append(list(train_index))\n",
    "        test_list.append(list(test_index))\n",
    "\n",
    "        count += 1\n",
    "  \n",
    "    return train_list, test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Fold 6\n",
      "Fold 7\n",
      "Fold 8\n",
      "Fold 9\n",
      "Fold 10\n"
     ]
    }
   ],
   "source": [
    "train_list, test_list = CreateFolds(X, y, 10, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_idx = pd.DataFrame()\n",
    "for i,n in enumerate(train_list):\n",
    "    df_train_idx['fold{}'.format(i+1)] = n\n",
    "        \n",
    "df_test_idx = pd.DataFrame()\n",
    "for i,n in enumerate(test_list):\n",
    "    df_test_idx['fold{}'.format(i+1)] = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_idx.to_csv('./df_train_idx.csv')\n",
    "df_test_idx.to_csv('./df_test_idx.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "9hBDiO10vxJJ"
   },
   "outputs": [],
   "source": [
    "df_train_idx = pd.read_csv('./df_train_10folds.csv', index_col=0)\n",
    "df_test_idx = pd.read_csv('./df_test_10folds.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "-uCr7TS9vyx8"
   },
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 3:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYo6mK5wOcR-"
   },
   "source": [
    "# 10-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hSw2JFtyOedR",
    "outputId": "d122e39a-316d-4a0b-e0b2-84600c6cf601"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biLSTMAtt\n",
      "Fold 1, lr: 0.008, D: 10\n",
      "Epoch 1/10\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.00800000037997961.\n",
      " 14/158 [=>............................] - ETA: 1:48 - loss: 2.5715 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5376.0000 - fn: 448.0000 - accuracy: 0.9231 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5178"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13388/3761729070.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m     history = model.fit(X_train, y_train, epochs=10,\n\u001b[0;32m     21\u001b[0m                       \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m                       callbacks=[callback])\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mhist_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\novo\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\novo\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\novo\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\novo\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 3040\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3042\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\novo\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1964\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\novo\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    597\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\novo\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = 0 # last trained fold\n",
    "model_name = 'biLSTMAtt'\n",
    "\n",
    "d = 10\n",
    "lr = 0.008\n",
    "\n",
    "for i in range(start, 10):\n",
    "    print(model_name)\n",
    "    print('Fold {}, lr: {}, D: {}'.format(i+1, lr, d))\n",
    "    X_train = X[df_train_idx['fold{}'.format(i+1)]]\n",
    "    X_test = X[df_test_idx['fold{}'.format(i+1)]]\n",
    "\n",
    "    y_train = y[df_train_idx['fold{}'.format(i+1)]]\n",
    "    y_test = y[df_test_idx['fold{}'.format(i+1)]]\n",
    "\n",
    "    callback = tf.keras.callbacks.LearningRateScheduler(scheduler, verbose=1)\n",
    "\n",
    "    # MODEL\n",
    "    model = biLSTMAtt(lr,d)\n",
    "    history = model.fit(X_train, y_train, epochs=10,\n",
    "                      validation_data=(X_test, y_test),\n",
    "                      callbacks=[callback])\n",
    "\n",
    "    hist_df = pd.DataFrame(history.history) \n",
    "    hist_csv_file = './history-{}-lr{}-D{}-{}epochs-fold{}-dropout40.csv'.format(model_name,\n",
    "                                                                                 lr, d, '10', i)\n",
    "\n",
    "    with open(hist_csv_file, mode='w') as f:\n",
    "        hist_df.to_csv(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8MybcaOBO_QL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NCYPred-comparar-DL-algoritmos.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
